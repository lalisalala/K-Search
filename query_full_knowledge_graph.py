from rdflib import Graph
import logging
from llm_chatbot import LLMChatbot

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize the LLMChatbot with Mistral
chatbot = LLMChatbot(model_name="mistral", temperature=0, max_tokens=500, api_url="http://localhost:11434/api/generate")

# Static SPARQL Query Template
SPARQL_TEMPLATE = """
PREFIX ex: <http://example.org/ontology/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX schema: <https://schema.org/>
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>

SELECT DISTINCT ?dataset ?label ?summary ?fileFormat ?url ?publisher
WHERE {
  ?dataset a ex:Dataset .
  OPTIONAL { ?dataset rdfs:label ?label . }
  OPTIONAL { ?dataset ex:summary ?summary . }
  OPTIONAL { ?dataset ex:fileFormat ?fileFormat . }
  OPTIONAL { ?dataset schema:url ?url . }
  OPTIONAL { ?dataset ex:publisher ?publisher . }
  OPTIONAL { ?dataset ex:hasTopic ?topic . }
  {filters}
}
"""

PREDEFINED_TOPICS = [
    "Demographics", "Environment", "Employment and Skills", "Planning", "Transparency",
    "Business and Economy", "Housing", "Health", "Education", "Transport",
    "Crime and Community Safety", "Young People", "Income, Poverty, and Welfare",
    "Art and Culture", "COVID-19 Data and Analysis", "Championing London",
    "Sport", "London 2012"
]

def load_valid_topics():
    """
    Load predefined valid topics for assigning in SPARQL queries.
    """
    return PREDEFINED_TOPICS

def validate_assigned_topics(assigned_topics):
    """
    Ensure that the topics assigned by the LLM are part of the predefined list.
    """
    return [topic for topic in assigned_topics if topic in PREDEFINED_TOPICS]

def generate_sparql_query_with_llm(user_query):
    """
    Use the LLM to analyze the user query and generate a SPARQL query using the template.
    """
    prompt = (
        "### Task\n"
        "You are a SPARQL query assistant. Your job is to generate a SPARQL query based on the user's natural language query. "
        "Replace the {filters} placeholder in the template with valid SPARQL FILTER statements derived from the user's query. "
        "Your task includes assigning one or more of the following topics to the query:\n"
        f"{', '.join(PREDEFINED_TOPICS)}.\n"
        "Based on the user's query, suggest the most relevant topics from this list for `ex:hasTopic`.\n"
        "Output only the SPARQL query. Do not include explanations, commentary, or unrelated text.\n\n"
        "### SPARQL Template\n"
        f"{SPARQL_TEMPLATE}\n\n"
        "### Example\n"
        "User Query: Find datasets about air quality in CSV format.\n"
        "SPARQL Query:\n"
        "PREFIX ex: <http://example.org/ontology/>\n"
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n"
        "PREFIX schema: <https://schema.org/>\n"
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n\n"
        "SELECT DISTINCT ?dataset ?label ?summary ?fileFormat ?url ?publisher\n"
        "WHERE {\n"
        "  ?dataset a ex:Dataset .\n"
        "  OPTIONAL { ?dataset rdfs:label ?label . }\n"
        "  OPTIONAL { ?dataset ex:summary ?summary . }\n"
        "  OPTIONAL { ?dataset ex:fileFormat ?fileFormat . }\n"
        "  OPTIONAL { ?dataset schema:url ?url . }\n"
        "  OPTIONAL { ?dataset ex:publisher ?publisher . }\n"
        "  OPTIONAL { ?dataset ex:hasTopic ?topic . }\n"
        "  FILTER (CONTAINS(LCASE(STR(?label)), \"air quality\") || CONTAINS(LCASE(STR(?summary)), \"air quality\"))\n"
        "  FILTER (?topic IN (ex:Environment))\n"
        "  FILTER (LCASE(STR(?fileFormat)) = \"csv\")\n"
        "}\n\n"
        "### User Query\n"
        f"{user_query}\n\n"
        "### SPARQL Query"
    )

    try:
        llm_response = chatbot.generate_response(prompt)
        sparql_query = llm_response.strip()

        # Extract topics generated by the LLM (use simple regex or logic if needed)
        generated_topics = [topic.strip() for topic in PREDEFINED_TOPICS if topic.lower() in sparql_query.lower()]
        validated_topics = validate_assigned_topics(generated_topics)

        # Replace the {filters} placeholder with the validated topics
        if validated_topics:
            topic_filter = f"FILTER (?topic IN ({', '.join(f'ex:{topic.replace(' ', '_')}' for topic in validated_topics)}))"
        else:
            topic_filter = ""

        sparql_query = sparql_query.replace("{filters}", topic_filter)

        # Validate SPARQL query structure
        if not validate_sparql_output(sparql_query):
            logger.error("SPARQL query validation failed.")
            return None

        logger.info(f"Generated SPARQL Query:\n{sparql_query}")
        return sparql_query
    except Exception as e:
        logger.error(f"Error generating SPARQL query with LLM: {e}")
        return None

def validate_sparql_output(sparql_query):
    """
    Validate the SPARQL query to ensure it contains no extraneous text.
    """
    if "In this case" in sparql_query or "explanations" in sparql_query:
        logger.error("Generated SPARQL query contains extraneous text.")
        return False
    return True

def query_knowledge_graph(query_string, rdf_file='updated_metadata_ontology3.ttl'):
    """
    Query the RDF knowledge graph with the SPARQL query.
    """
    g = Graph()
    try:
        g.parse(rdf_file, format="turtle")
        logger.info(f"Graph contains {len(g)} triples.")
    except FileNotFoundError:
        logger.error(f"RDF file '{rdf_file}' not found.")
        return []

    try:
        logger.info(f"Executing SPARQL Query:\n{query_string}")
        results = g.query(query_string)
        return [{str(var): row[var] for var in row.labels} for row in results]
    except Exception as e:
        logger.error(f"Error executing SPARQL query: {e}")
        return []

def main():
    user_query = input("Enter your dataset query (e.g., 'I am looking for a dataset in csv format about air quality'): ").strip()
    sparql_query = generate_sparql_query_with_llm(user_query)

    if sparql_query:
        results = query_knowledge_graph(sparql_query)
        if results:
            print("\nRelevant Datasets Found:\n")
            for idx, result in enumerate(results, start=1):
                print(f"Dataset {idx}:")
                print(f"Title: {result.get('label', 'N/A')}")
                print(f"Summary: {result.get('summary', 'N/A')}")
                print(f"File Format: {result.get('fileFormat', 'N/A')}")
                print(f"Publisher: {result.get('publisher', 'N/A')}")
                print(f"Link: {result.get('url', 'N/A')}")
                print()
        else:
            print("\nNo relevant datasets found.")
    else:
        print("Failed to generate a SPARQL query.")

if __name__ == "__main__":
    main()
